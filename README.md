<div align="center">

  # ğŸš€ CIFAR-10 Image Classification Project

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red)
![Status](https://img.shields.io/badge/Status-Completed-brightgreen)
</div>

## ğŸ§¾ Overview

This project explores three machine learning approaches for **CIFAR-10 image classification**:

- ğŸ¯ **PCA-based Classifier**
- ğŸ§  **Convolutional Neural Network (CNN)**
- ğŸ” **Class-wise Autoencoders**

The goal is to compare performance across methods and analyze their effectiveness on this challenging dataset.

## ğŸ“½ï¸ Demo

<video width="640" height="360" controls>
  <source src="video.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

## ğŸ“ Dataset

We use the **CIFAR-10** dataset:
- 60,000 32x32 color images
- 10 distinct classes (airplane, car, bird, cat, deer, dog, frog, horse, ship, truck)
- Split: 50,000 train / 10,000 test

ğŸ“¦ **Note**: Dataset not included in this repository due to size limits (>100MB). It will be auto-downloaded using `torchvision.datasets`.


## ğŸ§  Model Architecture Flow

```mermaid
graph LR
A[CIFAR-10 Dataset] --> B[PCA Classifier]
A --> C["Neural Network - CNN"]
A --> D[Class-wise Autoencoder]
B --> E[Prediction & Evaluation]
C --> E
D --> E
```




## ğŸ“Š Results Summary

| ğŸ”¬ Technique             | ğŸ¯ Best Accuracy |
|--------------------------|------------------|
| PCA Classifier           | 38.73%           |
| Convolutional Neural Net | 70.98%           |
| Class-wise Autoencoder   | 43.69%           |

âœ… **Best Performer**: **CNN with 70.98% accuracy**


## ğŸ”§ Implementation Breakdown

### 1ï¸âƒ£ PCA Classifier
- Separate PCA models per class  
- Images reconstructed using class-specific PCA  
- Class with **lowest reconstruction error** is predicted  
- **Best hyperparameter**: `k = 40` components


### 2ï¸âƒ£ Convolutional Neural Network (PyTorch)

```python
# Architecture
Conv2d(3, 32) â†’ ReLU â†’ MaxPool
â†’ Conv2d(32, 64) â†’ ReLU â†’ MaxPool
â†’ Flatten â†’ Linear(1600, 128) â†’ ReLU
â†’ Linear(128, 10)
```

- Optimizer: **Adam**  
- **Best Params**: Learning Rate = `0.0005`, Batch Size = `128`  
- Trained for **20 epochs**


### 3ï¸âƒ£ Class-wise Autoencoder
- A separate autoencoder is trained for **each class**  
- During inference, compute reconstruction error from each model  
- Predict label based on **minimum reconstruction error**  
- **Best Encoding Dimension**: `128`


## âš™ï¸ Setup & Usage

### ğŸ”¨ Install Dependencies
```bash
pip install torch torchvision numpy matplotlib
```

### ğŸš€ Run the Project
```bash
git clone https://github.com/yourusername/cifar10-classification.git
cd cifar10-classification

python main.py
```

---

## ğŸ“‚ Project Structure
```bash
cifar10-classification/
â”œâ”€â”€ data/                  # CIFAR-10 dataset (auto-downloaded)
â”œâ”€â”€ task1_pca/             # PCA classification
â”œâ”€â”€ task2_nn/              # CNN implementation
â”œâ”€â”€ task3_autoencoder/     # Class-wise autoencoders
â”œâ”€â”€ utils/                 # Utility scripts
â”œâ”€â”€ main.py                # Master runner script
â””â”€â”€ README.md              # This file
```

---

## ğŸ” Key Observations

- ğŸ“ˆ **CNN dominates** with highest accuracy and generalization  
- ğŸ§© **PCA** performs poorly beyond `k=40` due to limited representation  
- ğŸ§  **Autoencoders** outperform PCA but require more computation and tuning  
- âš™ï¸ Hyperparameters like **LR** and **encoding dimension** were critical to success

---








